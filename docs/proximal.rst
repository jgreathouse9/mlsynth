Proximal Synthetic Control
==========================

Next, I discuss the proximal SCM method. In synthetic control methods, we oftentimes make the presumption that our outcomes are generated by some latent variable model, :math:`y_{jt} = \delta_t + \lambda_t\mu_j+\epsilon_{jt}`. This data-generating process may include covariates, but the basic idea is that there are a set of common time effects which impact all units the same and unit-specific effects, which interact with the former, which generates the outcomes that we see we see. Abadie and co [ABADIE2010]_ and others ues this linear factor model to justify SCM. They also derive a bias boud for the SCM, which is (with qualifications) unbiased as the the number of pre-treatment periods grows without bound. This, naturally, poses a problem in settings where we have few pre-treatment periods. Additionally, it may not always be possible to obtain good pre-treatment fit, even if we are mathching on the time-variant factors by regressing our treated unit's outcomes upon our donor units. As a result, the Proximal Inference SCM was developed. In the paper, Shi, Li, Miao, Hu, and Tchetgen Tchetgen [ProxSCM]_



   argue that the outcomes of control units are essentially proxies of the latent factors. Rather than directly regressing the outcome on all such proxies, one can split the set of  proxies into two, thus leveraging one set of proxies to assist the construction of a SC defined in terms of the other set of proxies.


In other words, if we agree that the outcomes of the control units are time variant proxies for our control units, we may be able to still employ the outcomes of other control units, repurposing them for matching on the latent time variant factors instead of learning the weights. This page describes, broadly, the three methods they propose, and applies it to an emprical example.

Notations
----------

Formally, let us define the notation. We observe a set of units indexed by :math:`j`, where 
:math:`\mathcal{N} \operatorname*{:=} \{1, 2, \ldots, N\}` is the set of all units, with cardinality 
:math:`N = |\mathcal{N}|`. Let :math:`j = 1` represent the treated unit, and 
:math:`\mathcal{N}_0 \operatorname*{:=} \mathcal{N} \setminus \{1\}` denote the set of control units, 
with cardinality :math:`N_0 = |\mathcal{N}_0|`. The time periods are indexed by :math:`t`, with 
:math:`\mathcal{T}_1 \operatorname*{:=} \{1, 2, \ldots, T_0\}` representing the pre-intervention periods 
and :math:`\mathcal{T}_2 \operatorname*{:=} \{T_0 + 1, \ldots, T\}` representing the post-intervention periods. 
We denote the full time series as :math:`\mathcal{T} \operatorname*{:=} \mathcal{T}_1 \cup \mathcal{T}_2`, 
with :math:`T = |\mathcal{T}|` representing the total number of time periods.

Let :math:`\mathbf{y}_1 \in \mathbb{R}^T` be the vector for the treated unit's outcomes, and 
:math:`\mathbf{Y}_0 \in \mathbb{R}^{T \times N_0}` be the matrix containing the outcomes of the control units. 
Let :math:`\mathbf{P}_t \in \mathbb{R}^{k \times T}` be a matrix of proxy variables that are assumed to be 
correlated with the common factors driving the outcomes of the treated unit. Here, :math:`k` represents the 
number of proxy variables. Let :math:`\mathbf{w} \in \mathbb{R}^{N_0}` represent the vector of weights for the synthetic control.

Shi, Li, Miao, Hu, and Tchetgen Tchetgen [ProxSCM]_ advocate for a GMM approach, defining the estimating function for the proximal synthetic control method as:

.. math::

    U_t(\mathbf{w}) = g(\mathbf{P}_t) \cdot \left( \mathbf{y}_1 - (\mathbf{Y}_0 \mathbf{w})_t \right),

where :math:`g(\mathbf{P}_t)` is a function applied to the proxy variables :math:`\mathbf{P}_t` at time :math:`t`, 
and :math:`\mathbf{y}_1` and :math:`(\mathbf{Y}_0 \mathbf{w})_t` are the observed and predicted outcomes at time 
:math:`t`, respectively. In this setup, the :math:`\mathbf{P}_t` matrix may be comprised of anything we believe to be correlated with the time variant common factors. Per HCW [HCW]_, the outcomes of other donor units is one example of this, or other covariates that are unaffected by the treatment but are correlated with the time latent factors.

The goal is to estimate the weights :math:`\mathbf{w}` by solving a quadratic programming problem which minimizes the moment conditions

.. math::

    \mathbf{w} = \arg\min_{\mathbf{w}} \sum_{t \in \mathcal{T}_1} U_t(\mathbf{w})^\top \Omega^{-1} U_t(\mathbf{w}),

where :math:`\Omega` is the covariance matrix of the estimating function.

Once we have our where, we math estimate the treatment effect like

.. math::

    \tau = \mathbf{y}_1 - \mathbf{Y}_0 \mathbf{w},

where the sample average of this over the post-intervention period is the ATT. To compute inference, we first estimate the variance-covariance matrix of the moment conditions, denoted by 
:math:`\boldsymbol{\Omega}`. This is done using a HAC estimator. 
The matrix :math:`\boldsymbol{\Omega}` is computed as:

.. math::

    \boldsymbol{\Omega} = \frac{1}{T} \sum_{j=-J}^{J} k(j, J) \sum_{t=1}^{T - |j|} \mathbf{g}_t \mathbf{g}_{t+j}^\top,

where :math:`k(j, J)` is the Bartlett kernel, :math:`J` is the bandwidth, and 
:math:`\mathbf{g}_t` is the vector of moment conditions at time :math:`t`. The outer summation runs over all lags 
within the valid range, while the inner summation computes the covariance contribution for each lag.

We now calculate the covariance matrix 
of the parameters as:

.. math::

    \text{Cov} = \mathbf{G}^{-1} \boldsymbol{\Omega} \left(\mathbf{G}^{-1}\right)^\top,

The variance of the ATT estimate :math:`\tau` is then extracted from the covariance matrix as:

.. math::

    \text{Var}(\tau) = \text{Cov}[-1, -1],

where :math:`\text{Cov}[-1, -1]` refers to the bottom-right entry of the covariance matrix. Finally, the standard error 
of :math:`\tau` is computed as:

.. math::

    \text{SE}(\tau) = \sqrt{\frac{\text{Var}(\tau)}{T}}.


Surrogate Approach 
--------------------

We may also employ surrogates, or post-intervention metrics which capture latent factors that drive the outcomes of the treated unit. Let :math`\mathbf{X}_t \in \mathbb{R}^H` represent a vector of observed surrogates for the treated unit, where :math`H` is the number of surrogate variables. These surrogates are chosen such that they are highly predictive of the treatment effects. The treatment effect is decomposed into two components, :math`Y_t(1) - Y_t(0) = \boldsymbol{\rho}_t^\top \boldsymbol{\theta} + \delta_t`, where :math`\boldsymbol{\rho}_t \in \mathbb{R}^K` is a vector of latent factors, :math`\boldsymbol{\theta} \in \mathbb{R}^K` is a vector of factor loadings, and :math`\delta_t` represents an error term uncorrelated with the latent factors.  

The surrogates :math`\mathbf{X}_t` follow a similar factor model, :math`\mathbf{X}_t^\top = \boldsymbol{\rho}_t^\top \mathbf{\Phi} + \boldsymbol{\epsilon}_{X,t}^\top`, where :math`\mathbf{\Phi} \in \mathbb{R}^{K \times H}` is a matrix of factor loadings for the surrogates, and :math`\boldsymbol{\epsilon}_{X,t}`is an error term for the surrogates. In this framework, proxies are introduced for donors and surrogates. Let \( \mathbf{P}_{0,t} \) represent proxy variables for donor outcomes, assumed to capture latent factors \( \boldsymbol{\lambda}_t \), and let \( \mathbf{P}_{1,t} \) represent proxy variables for surrogates, capturing both donor latent factors \( \boldsymbol{\lambda}_t \) and surrogate latent factors \( \boldsymbol{\rho}_t \).

The identification of this model relies on specific moment conditions. In the pre-treatment period, \( \mathbb{E}[Y_t - \mathbf{W}_t^\top \boldsymbol{\alpha} \mid \mathbf{Z}_{0,t}, t \leq T_0] = 0 \). In the post-treatment period, \( \mathbb{E}[Y_t - \mathbf{W}_t^\top \boldsymbol{\alpha} - \mathbf{X}_t^\top \boldsymbol{\gamma} \mid \mathbf{Z}_{0,t}, \mathbf{Z}_{1,t}, t > T_0] = 0 \). To ensure identification, there must exist weights \( \boldsymbol{\alpha} \in \mathbb{R}^{N} \) for donors such that \( \mathbf{\Gamma} \boldsymbol{\alpha} = \boldsymbol{\beta} \), where \( \mathbf{\Gamma} \) and \( \boldsymbol{\beta} \) represent factor loadings. Similarly, there must exist weights \( \boldsymbol{\gamma} \in \mathbb{R}^H \) for surrogates such that \( \mathbf{\Phi} \boldsymbol{\gamma} = \boldsymbol{\theta} \).

The Average Treatment Effect on the Treated (ATT) is expressed as \( \tau = \frac{1}{T - T_0} \sum_{t > T_0} \mathbf{X}_t^\top \boldsymbol{\gamma} \), where the surrogate coefficients \( \boldsymbol{\gamma} \) are estimated from the post-treatment period. Alternatively, the ATT can be calculated as \( \tau = \frac{1}{T - T_0} \sum_{t > T_0} \left( Y_t - \mathbf{W}_t^\top \boldsymbol{\alpha} \right) \). This formulation leverages surrogate variables and proxies to enhance the synthetic control framework, providing improved estimates of treatment effects, particularly in settings with latent factors and limited pre-treatment data.


.. autoclass:: mlsynth.mlsynth.PROXIMAL
   :show-inheritance:
   :special-members: __init__




Estimating Proximal SCM via ``mlsynth``
--------------------------------------------


This is the plot we get when we estimate the causal impact.


.. image:: https://raw.githubusercontent.com/jgreathouse9/mlsynth/refs/heads/main/examples/PROXIMAL/PanicProx.png
   :alt: Proximal Synthetic Control Estimation
   :align: center
   :width: 600px


As we can see, even when we use only post-intervention data to estimate the causal impact, the result largely agrees with the original estimates.
